{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad12fef-d62d-46e7-983a-01789305daf4",
   "metadata": {},
   "source": [
    "https://sagemaker-examples.readthedocs.io/en/latest/frameworks/tensorflow/get_started_mnist_train.html#TensorFlow-Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554a5e8f-db35-4d70-8b00-1b15b933f7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5958150-f1b4-4758-8165-519e649ee75a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Model, Sequential\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlayers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dense\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m, \u001b[04m\u001b[36mgc\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mTF_CPP_MIN_LOG_LEVEL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[33m'\u001b[39;49;00m\u001b[33m2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m, \u001b[04m\u001b[36mdatetime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtqdm\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m tqdm\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mload_dataset\u001b[39;49;00m(s3_loc, s3_filename):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    data = np.load(os.path.join(s3_loc, s3_filename))\u001b[37m\u001b[39;49;00m\n",
      "    feature_cols = [\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mfeature_\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m:\u001b[39;49;00m\u001b[33m02d\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m79\u001b[39;49;00m)]\u001b[37m\u001b[39;49;00m\n",
      "    features = {col: data[col] \u001b[34mfor\u001b[39;49;00m col \u001b[35min\u001b[39;49;00m feature_cols}\u001b[37m\u001b[39;49;00m\n",
      "    x = np.column_stack([features[col] \u001b[34mfor\u001b[39;49;00m col \u001b[35min\u001b[39;49;00m feature_cols])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInput shape: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mx.shape\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdel\u001b[39;49;00m features\u001b[37m\u001b[39;49;00m\n",
      "    gc.collect()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m x\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mAutoEncoderTrainOnly\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x_train, params):      \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.x_train = x_train\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.input_size = x_train.shape[\u001b[34m1\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.latent_dim = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mlatent_dim\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.n_enc_1 = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_enc_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.n_enc_2 = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_enc_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.n_dec_1 = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_dec_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.n_dec_2 = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_dec_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.lr = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mlr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.batch_size = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.epochs = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mepochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.model = \u001b[36mself\u001b[39;49;00m.build_autoencoder()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.loss_fn = tf.keras.losses.MeanSquaredError()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.optimizer = tf.keras.optimizers.Adam(learning_rate=\u001b[36mself\u001b[39;49;00m.lr)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.train_ds = \u001b[36mself\u001b[39;49;00m.create_tf_datasets()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.model_dir = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mbuild_autoencoder\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.encoder = \u001b[36mself\u001b[39;49;00m.build_encoder()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.decoder = \u001b[36mself\u001b[39;49;00m.build_decoder()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        input_layer = tf.keras.Input(shape=(\u001b[36mself\u001b[39;49;00m.input_size,))\u001b[37m\u001b[39;49;00m\n",
      "        encoded_output = \u001b[36mself\u001b[39;49;00m.encoder(input_layer)\u001b[37m\u001b[39;49;00m\n",
      "        decoded_output = \u001b[36mself\u001b[39;49;00m.decoder(encoded_output)\u001b[37m\u001b[39;49;00m\n",
      "        model = Model(inputs=input_layer, outputs=decoded_output)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model.compile(optimizer=self.optimizer, loss=self.loss_fn,)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m model\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mbuild_encoder\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        encoder = Sequential([\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.n_enc_1, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, input_shape=(\u001b[36mself\u001b[39;49;00m.input_size,)),\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.n_enc_2, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.latent_dim, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        ])\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m encoder\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mbuild_decoder\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        decoder= Sequential([\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.n_dec_1, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, input_shape=(\u001b[36mself\u001b[39;49;00m.latent_dim, )),\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.n_dec_2, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.input_size, activation=\u001b[34mNone\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        ])\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m decoder\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[90m@tf\u001b[39;49;00m.function\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtrain_step\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, inputs):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m tf.GradientTape() \u001b[34mas\u001b[39;49;00m tape:\u001b[37m\u001b[39;49;00m\n",
      "            reconstructed = \u001b[36mself\u001b[39;49;00m.model(inputs, training=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            loss = \u001b[36mself\u001b[39;49;00m.loss_fn(inputs, reconstructed)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        gradients = tape.gradient(loss, \u001b[36mself\u001b[39;49;00m.model.trainable_variables)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.optimizer.apply_gradients(\u001b[36mzip\u001b[39;49;00m(gradients, \u001b[36mself\u001b[39;49;00m.model.trainable_variables))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m loss\u001b[37m\u001b[39;49;00m\n",
      "                  \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_tf_datasets\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        train_dataset = tf.data.Dataset.from_tensor_slices(\u001b[36mself\u001b[39;49;00m.x_train)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        train_dataset = (\u001b[37m\u001b[39;49;00m\n",
      "            train_dataset.shuffle(buffer_size=\u001b[34m100000\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            .batch(batch_size=\u001b[36mself\u001b[39;49;00m.batch_size)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            .prefetch(buffer_size=\u001b[34m2\u001b[39;49;00m) \u001b[37m# prefetch next 2 batches in memory while training\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m train_dataset\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mfit\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m tqdm(\u001b[36mrange\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.epochs), leave=\u001b[34mFalse\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            training_loss = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m step, batch \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.train_ds, start=\u001b[34m1\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "                loss = \u001b[36mself\u001b[39;49;00m.train_step(batch)\u001b[37m\u001b[39;49;00m\n",
      "                training_loss += loss\u001b[37m\u001b[39;49;00m\n",
      "            training_loss /= step\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            tqdm.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch+\u001b[34m1\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m| Training loss: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtraining_loss\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msave_artifacts\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, save_weights=\u001b[34mTrue\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "         \u001b[37m#---\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Save model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        version = \u001b[33m\"\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        ckpt_dir = os.path.join(\u001b[36mself\u001b[39;49;00m.model_dir, version)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.exists(ckpt_dir):\u001b[37m\u001b[39;49;00m\n",
      "            os.makedirs(ckpt_dir)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m save_weights:\u001b[37m\u001b[39;49;00m\n",
      "            weights_suffix = \u001b[33m\"\u001b[39;49;00m\u001b[33m.weights\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m: \u001b[37m\u001b[39;49;00m\n",
      "            weights_suffix = \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        model_save_path = os.path.join(ckpt_dir, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mweights_suffix\u001b[33m}\u001b[39;49;00m\u001b[33m.h5\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        encoder_save_path = os.path.join(ckpt_dir, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mencoder\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mweights_suffix\u001b[33m}\u001b[39;49;00m\u001b[33m.h5\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        decoder_save_path = os.path.join(ckpt_dir, \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mdecoder\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mweights_suffix\u001b[33m}\u001b[39;49;00m\u001b[33m.h5\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m save_weights:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving model weights to: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mself\u001b[39;49;00m.model_dir\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.model.save_weights(model_save_path)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.encoder.save_weights(encoder_save_path)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.decoder.save_weights(decoder_save_path)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.model.save(model_save_path)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.encoder.save(encoder_save_path)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.decoder.save(decoder_save_path)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Save encoded output\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        x_encoded = \u001b[36mself\u001b[39;49;00m.encoder.predict(\u001b[36mself\u001b[39;49;00m.x_train)\u001b[37m\u001b[39;49;00m\n",
      "        encoded_save_path = os.path.join(ckpt_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mx_encoded.npz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        np.savez_compressed(encoded_save_path, array=x_encoded)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m#---\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mTrainingJob\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[90m@staticmethod\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "        parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Hyperparameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m1e-3\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--latent_dim\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m16\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_enc_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_enc_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_dec_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_dec_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--s3_filename\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mdf_530_lite.npz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Sagemaker Job parameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m parser.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mrun\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        args = \u001b[36mself\u001b[39;49;00m.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "        x = load_dataset(args.train, args.s3_filename)\u001b[37m\u001b[39;49;00m\n",
      "        params = {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn_enc_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_enc_1,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn_enc_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_enc_2,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn_dec_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_dec_1,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn_dec_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_dec_2,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mepochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.epochs,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mlr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.learning_rate,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.batch_size,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mlatent_dim\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.latent_dim,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.model_dir,\u001b[37m\u001b[39;49;00m\n",
      "        }\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m tf.device(\u001b[33m\"\u001b[39;49;00m\u001b[33m/device:GPU:0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            ae = AutoEncoderTrainOnly(x, params)\u001b[37m\u001b[39;49;00m\n",
      "            ae.fit()\u001b[37m\u001b[39;49;00m\n",
      "            ae.save_artifacts()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    tj = TrainingJob()\u001b[37m\u001b[39;49;00m\n",
      "    tj.run()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize '../trainer/autoencoder.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1e150b-3899-461e-87c1-ab7f5c4d64fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set local_mode to be True if you want to run the training script on the machine that runs this notebook\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.g4dn.8xlarge\"\n",
    "    \n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S%f\")[2:17]\n",
    "output_path = \"s3://kedrobucket/supply_chain_data_asset_shr/training/jane_st_forecasting\"\n",
    "# model_dir = os.path.join(output_path, f\"tensorflow_training_{timestamp}\")\n",
    "# print(model_dir)\n",
    "est = TensorFlow(\n",
    "    entry_point=\"autoencoder.py\",\n",
    "    source_dir=\"../trainer\",  # directory of your training script\n",
    "    role=role,\n",
    "    framework_version=\"2.16\",\n",
    "    model_dir=False,\n",
    "    py_version=\"py310\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    volume_size=80,\n",
    "    output_path=output_path,\n",
    "    hyperparameters={\n",
    "        \"batch_size\": 256,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"s3_filename\": \"df_530_lite.npz\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982e017b-e9c6-4094-997c-5e478099b5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels = {\"training\": output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111f77d7-9699-4004-bd37-7f1ea40ca45b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: tensorflow-training-2024-10-25-03-34-40-506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-25 03:34:43 Starting - Starting the training job...\n",
      "2024-10-25 03:34:59 Starting - Preparing the instances for training...\n",
      "2024-10-25 03:35:32 Downloading - Downloading input data.....................\n",
      "2024-10-25 03:39:04 Training - Training image download completed. Training in progress...\u001b[34m/usr/local/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:21.795057: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:21.808976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:21.831385: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:21.831413: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:21.844886: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[0m\n",
      "\u001b[34mTo enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:23.252830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:24,328 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:24,347 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:24,705 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:24,738 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:24,770 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:24,784 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.8xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 256,\n",
      "        \"epochs\": 10,\n",
      "        \"learning_rate\": 0.001,\n",
      "        \"s3_filename\": \"df_530_lite.npz\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.8xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"tensorflow-training-2024-10-25-03-34-40-506\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://kedrobucket/tensorflow-training-2024-10-25-03-34-40-506/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"autoencoder\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.8xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.8xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"autoencoder.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":256,\"epochs\":10,\"learning_rate\":0.001,\"s3_filename\":\"df_530_lite.npz\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=autoencoder.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.8xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=autoencoder\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://kedrobucket/tensorflow-training-2024-10-25-03-34-40-506/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.8xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":256,\"epochs\":10,\"learning_rate\":0.001,\"s3_filename\":\"df_530_lite.npz\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"tensorflow-training-2024-10-25-03-34-40-506\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://kedrobucket/tensorflow-training-2024-10-25-03-34-40-506/source/sourcedir.tar.gz\",\"module_name\":\"autoencoder\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"autoencoder.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"256\",\"--epochs\",\"10\",\"--learning_rate\",\"0.001\",\"--s3_filename\",\"df_530_lite.npz\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_S3_FILENAME=df_530_lite.npz\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python310.zip:/usr/local/lib/python3.10:/usr/local/lib/python3.10/lib-dynload:/usr/local/lib/python3.10/site-packages:/usr/local/lib/python3.10/site-packages/setuptools/_vendor\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.10 autoencoder.py --batch_size 256 --epochs 10 --learning_rate 0.001 --s3_filename df_530_lite.npz\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:24,785 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:25.159104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:25.180995: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:25.181028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:26.573668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[0m\n",
      "\u001b[34mInput shape: (71316, 79)\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\u001b[0m\n",
      "\u001b[34m0%|          | 0/10 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:32.472585: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 1| Training loss: 77.12\u001b[0m\n",
      "\u001b[34m0%|          | 0/10 [00:03<?, ?it/s]#015 10%|█         | 1/10 [00:03<00:29,  3.23s/it]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:33.397110: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 2| Training loss: 0.83\u001b[0m\n",
      "\u001b[34m10%|█         | 1/10 [00:04<00:29,  3.23s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 2/10 [00:04<00:14,  1.87s/it]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:34.313970: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 3| Training loss: 0.56\u001b[0m\n",
      "\u001b[34m20%|██        | 2/10 [00:05<00:14,  1.87s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 3/10 [00:05<00:10,  1.44s/it]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:35.226763: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 4| Training loss: 0.49\u001b[0m\n",
      "\u001b[34m30%|███       | 3/10 [00:05<00:10,  1.44s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 4/10 [00:05<00:07,  1.23s/it]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:36.141587: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 5| Training loss: 0.45\u001b[0m\n",
      "\u001b[34m40%|████      | 4/10 [00:06<00:07,  1.23s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 5/10 [00:06<00:05,  1.12s/it]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:37.125249: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 6| Training loss: 0.44\u001b[0m\n",
      "\u001b[34m50%|█████     | 5/10 [00:07<00:05,  1.12s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 6/10 [00:07<00:04,  1.07s/it]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:38.226595: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 7| Training loss: 0.41\u001b[0m\n",
      "\u001b[34m60%|██████    | 6/10 [00:08<00:04,  1.07s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 7/10 [00:08<00:03,  1.08s/it]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:39.149012: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 8| Training loss: 0.40\u001b[0m\n",
      "\u001b[34m70%|███████   | 7/10 [00:09<00:03,  1.08s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 8/10 [00:09<00:02,  1.03s/it]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:40.072998: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 9| Training loss: 0.39\u001b[0m\n",
      "\u001b[34m80%|████████  | 8/10 [00:10<00:02,  1.03s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 9/10 [00:10<00:00,  1.00it/s]\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:40.983312: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\u001b[0m\n",
      "\u001b[34mEpoch: 10| Training loss: 0.38\u001b[0m\n",
      "\u001b[34m90%|█████████ | 9/10 [00:11<00:00,  1.00it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 10/10 [00:11<00:00,  1.03it/s]\u001b[0m\n",
      "\u001b[34mSaving model weights to: /opt/ml/model\u001b[0m\n",
      "\u001b[34mWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[0m\n",
      "\u001b[34mI0000 00:00:1729827581.151191     242 service.cc:145] XLA service 0x7f472c026070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34mI0000 00:00:1729827581.151229     242 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\u001b[0m\n",
      "\u001b[34mI0000 00:00:1729827581.297762     242 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\u001b[0m\n",
      "\u001b[34m#033[1m   1/2229#033[0m #033[37m━━━━━━━━━━━━━━━━━━━━#033[0m #033[1m7:58#033[0m 215ms/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m  56/2229#033[0m #033[37m━━━━━━━━━━━━━━━━━━━━#033[0m #033[1m2s#033[0m 923us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 112/2229#033[0m #033[32m━#033[0m#033[37m━━━━━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 911us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 168/2229#033[0m #033[32m━#033[0m#033[37m━━━━━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 905us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 224/2229#033[0m #033[32m━━#033[0m#033[37m━━━━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 903us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 280/2229#033[0m #033[32m━━#033[0m#033[37m━━━━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 902us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 336/2229#033[0m #033[32m━━━#033[0m#033[37m━━━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 902us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 392/2229#033[0m #033[32m━━━#033[0m#033[37m━━━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 902us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 449/2229#033[0m #033[32m━━━━#033[0m#033[37m━━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 900us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 506/2229#033[0m #033[32m━━━━#033[0m#033[37m━━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 899us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 563/2229#033[0m #033[32m━━━━━#033[0m#033[37m━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 898us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 619/2229#033[0m #033[32m━━━━━#033[0m#033[37m━━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 898us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 675/2229#033[0m #033[32m━━━━━━#033[0m#033[37m━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 898us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 731/2229#033[0m #033[32m━━━━━━#033[0m#033[37m━━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 898us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 787/2229#033[0m #033[32m━━━━━━━#033[0m#033[37m━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 898us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 844/2229#033[0m #033[32m━━━━━━━#033[0m#033[37m━━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 897us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 901/2229#033[0m #033[32m━━━━━━━━#033[0m#033[37m━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 896us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m 958/2229#033[0m #033[32m━━━━━━━━#033[0m#033[37m━━━━━━━━━━━━#033[0m #033[1m1s#033[0m 896us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1015/2229#033[0m #033[32m━━━━━━━━━#033[0m#033[37m━━━━━━━━━━━#033[0m #033[1m1s#033[0m 896us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1072/2229#033[0m #033[32m━━━━━━━━━#033[0m#033[37m━━━━━━━━━━━#033[0m #033[1m1s#033[0m 895us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1129/2229#033[0m #033[32m━━━━━━━━━━#033[0m#033[37m━━━━━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1186/2229#033[0m #033[32m━━━━━━━━━━#033[0m#033[37m━━━━━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1242/2229#033[0m #033[32m━━━━━━━━━━━#033[0m#033[37m━━━━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1298/2229#033[0m #033[32m━━━━━━━━━━━#033[0m#033[37m━━━━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1354/2229#033[0m #033[32m━━━━━━━━━━━━#033[0m#033[37m━━━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1411/2229#033[0m #033[32m━━━━━━━━━━━━#033[0m#033[37m━━━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1468/2229#033[0m #033[32m━━━━━━━━━━━━━#033[0m#033[37m━━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1525/2229#033[0m #033[32m━━━━━━━━━━━━━#033[0m#033[37m━━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1582/2229#033[0m #033[32m━━━━━━━━━━━━━━#033[0m#033[37m━━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1639/2229#033[0m #033[32m━━━━━━━━━━━━━━#033[0m#033[37m━━━━━━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1695/2229#033[0m #033[32m━━━━━━━━━━━━━━━#033[0m#033[37m━━━━━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1751/2229#033[0m #033[32m━━━━━━━━━━━━━━━#033[0m#033[37m━━━━━#033[0m #033[1m0s#033[0m 894us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1808/2229#033[0m #033[32m━━━━━━━━━━━━━━━━#033[0m#033[37m━━━━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1865/2229#033[0m #033[32m━━━━━━━━━━━━━━━━#033[0m#033[37m━━━━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1922/2229#033[0m #033[32m━━━━━━━━━━━━━━━━━#033[0m#033[37m━━━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m1978/2229#033[0m #033[32m━━━━━━━━━━━━━━━━━#033[0m#033[37m━━━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m2035/2229#033[0m #033[32m━━━━━━━━━━━━━━━━━━#033[0m#033[37m━━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m2092/2229#033[0m #033[32m━━━━━━━━━━━━━━━━━━#033[0m#033[37m━━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m2148/2229#033[0m #033[32m━━━━━━━━━━━━━━━━━━━#033[0m#033[37m━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m2204/2229#033[0m #033[32m━━━━━━━━━━━━━━━━━━━#033[0m#033[37m━#033[0m #033[1m0s#033[0m 893us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m2229/2229#033[0m #033[32m━━━━━━━━━━━━━━━━━━━━#033[0m#033[37m#033[0m #033[1m0s#033[0m 964us/step\u001b[0m\n",
      "\u001b[34m#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015#033[1m2229/2229#033[0m #033[32m━━━━━━━━━━━━━━━━━━━━#033[0m#033[37m#033[0m #033[1m2s#033[0m 964us/step\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:45,738 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:45,738 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:45,739 sagemaker_tensorflow_container.training WARNING  Your model will NOT be servable with SageMaker TensorFlow Serving container. The model artifact was not saved in the TensorFlow SavedModel directory structure:\u001b[0m\n",
      "\u001b[34mhttps://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory\u001b[0m\n",
      "\u001b[34m2024-10-25 03:39:45,739 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-10-25 03:40:02 Uploading - Uploading generated training model\n",
      "2024-10-25 03:40:02 Completed - Training job completed\n",
      "Training seconds: 270\n",
      "Billable seconds: 270\n"
     ]
    }
   ],
   "source": [
    "est.fit(inputs=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69177d03-5b2c-4328-bdd8-a475144b82f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://kedrobucket/supply_chain_data_asset_shr/training/jane_st_forecasting/tensorflow-training-2024-10-25-03-34-40-506/output/model.tar.gz to ../../outputs/tensorflow-training-2024-10-25-03-34-40-506/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Download outputs to local\n",
    "local_path = \"../../outputs/\"+est.model_data.split(\"jane_st_forecasting/\")[1]\n",
    "s3_path = est.model_data\n",
    "\n",
    "!aws s3 cp {s3_path} {local_path}\n",
    "\n",
    "# Extract downloaded outputs\n",
    "\n",
    "import tarfile\n",
    "\n",
    "# Specify the tar file and the directory to extract it to\n",
    "extract_to_dir = 'model'\n",
    "\n",
    "# Open the tar file\n",
    "with tarfile.open(local_path, \"r:gz\") as tar:  # Use \"r\" for uncompressed .tar files\n",
    "    tar.extractall(path=local_path.replace(\".tar.gz\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ebdf8-1cdc-4f92-b3d0-907e258d9f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
