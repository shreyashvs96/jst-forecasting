{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad12fef-d62d-46e7-983a-01789305daf4",
   "metadata": {},
   "source": [
    "https://sagemaker-examples.readthedocs.io/en/latest/frameworks/tensorflow/get_started_mnist_train.html#TensorFlow-Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554a5e8f-db35-4d70-8b00-1b15b933f7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5958150-f1b4-4758-8165-519e649ee75a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Model, Sequential\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlayers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dense\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m, \u001b[04m\u001b[36mgc\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mTF_CPP_MIN_LOG_LEVEL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[33m'\u001b[39;49;00m\u001b[33m2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m, \u001b[04m\u001b[36mdatetime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtqdm\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m tqdm\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mload_dataset\u001b[39;49;00m(s3_loc, s3_filename):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    data = np.load(os.path.join(s3_loc, s3_filename))\u001b[37m\u001b[39;49;00m\n",
      "    feature_cols = [\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mfeature_\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m:\u001b[39;49;00m\u001b[33m02d\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m79\u001b[39;49;00m)]\u001b[37m\u001b[39;49;00m\n",
      "    features = {col: data[col] \u001b[34mfor\u001b[39;49;00m col \u001b[35min\u001b[39;49;00m feature_cols}\u001b[37m\u001b[39;49;00m\n",
      "    x = np.column_stack([features[col] \u001b[34mfor\u001b[39;49;00m col \u001b[35min\u001b[39;49;00m feature_cols])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInput shape: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mx.shape\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdel\u001b[39;49;00m features\u001b[37m\u001b[39;49;00m\n",
      "    gc.collect()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m x\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mAutoEncoderTrainOnly\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x_train, params):      \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.x_train = x_train\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.input_size = x_train.shape[\u001b[34m1\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.latent_dim = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mlatent_dim\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.n_enc_1 = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_enc_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.n_enc_2 = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_enc_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.n_dec_1 = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_dec_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.n_dec_2 = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_dec_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.lr = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mlr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.batch_size = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.epochs = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mepochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.model = \u001b[36mself\u001b[39;49;00m.build_autoencoder()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.loss_fn = tf.keras.losses.MeanSquaredError()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.optimizer = tf.keras.optimizers.Adam(learning_rate=\u001b[36mself\u001b[39;49;00m.lr)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.train_ds = \u001b[36mself\u001b[39;49;00m.create_tf_datasets()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mbuild_autoencoder\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.encoder = \u001b[36mself\u001b[39;49;00m.build_encoder()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.decoder = \u001b[36mself\u001b[39;49;00m.build_decoder()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        input_layer = tf.keras.Input(shape=(\u001b[36mself\u001b[39;49;00m.input_size,))\u001b[37m\u001b[39;49;00m\n",
      "        encoded_output = \u001b[36mself\u001b[39;49;00m.encoder(input_layer)\u001b[37m\u001b[39;49;00m\n",
      "        decoded_output = \u001b[36mself\u001b[39;49;00m.decoder(encoded_output)\u001b[37m\u001b[39;49;00m\n",
      "        model = Model(inputs=input_layer, outputs=decoded_output)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# model.compile(optimizer=self.optimizer, loss=self.loss_fn,)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m model\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mbuild_encoder\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        encoder = Sequential([\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.n_enc_1, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, input_shape=(\u001b[36mself\u001b[39;49;00m.input_size,)),\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.n_enc_2, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.latent_dim, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        ])\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m encoder\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mbuild_decoder\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        decoder= Sequential([\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.n_dec_1, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, input_shape=(\u001b[36mself\u001b[39;49;00m.latent_dim, )),\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.n_dec_2, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "            Dense(\u001b[36mself\u001b[39;49;00m.input_size, activation=\u001b[34mNone\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        ])\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m decoder\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[90m@tf\u001b[39;49;00m.function\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtrain_step\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, inputs):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m tf.GradientTape() \u001b[34mas\u001b[39;49;00m tape:\u001b[37m\u001b[39;49;00m\n",
      "            reconstructed = \u001b[36mself\u001b[39;49;00m.model(inputs, training=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            loss = \u001b[36mself\u001b[39;49;00m.loss_fn(inputs, reconstructed)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        gradients = tape.gradient(loss, \u001b[36mself\u001b[39;49;00m.model.trainable_variables)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.optimizer.apply_gradients(\u001b[36mzip\u001b[39;49;00m(gradients, \u001b[36mself\u001b[39;49;00m.model.trainable_variables))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m loss\u001b[37m\u001b[39;49;00m\n",
      "                  \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_tf_datasets\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        train_dataset = tf.data.Dataset.from_tensor_slices(\u001b[36mself\u001b[39;49;00m.x_train)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        train_dataset = (\u001b[37m\u001b[39;49;00m\n",
      "            train_dataset.shuffle(buffer_size=\u001b[34m100000\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "            .batch(batch_size=\u001b[36mself\u001b[39;49;00m.batch_size)\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m# .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            .prefetch(buffer_size=\u001b[34m2\u001b[39;49;00m) \u001b[37m# prefetch next 2 batches in memory while training\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m train_dataset\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mfit\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m tqdm(\u001b[36mrange\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.epochs), leave=\u001b[34mFalse\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            training_loss = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m step, batch \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.train_ds, start=\u001b[34m1\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "                loss = \u001b[36mself\u001b[39;49;00m.train_step(batch)\u001b[37m\u001b[39;49;00m\n",
      "                training_loss += loss\u001b[37m\u001b[39;49;00m\n",
      "            training_loss /= step\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "            tqdm.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mepoch+\u001b[34m1\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m| Training loss: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtraining_loss\u001b[33m:\u001b[39;49;00m\u001b[33m.2f\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mTrainingJob\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[90m@staticmethod\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "        parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Hyperparameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m1e-3\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--latent_dim\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m16\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_enc_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_enc_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_dec_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_dec_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--s3_filename\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mdf_530_lite.npz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Sagemaker Job parameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m parser.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mrun\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        args = \u001b[36mself\u001b[39;49;00m.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "        x = load_dataset(args.train, args.s3_filename)\u001b[37m\u001b[39;49;00m\n",
      "        params = {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn_enc_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_enc_1,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn_enc_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_enc_2,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn_dec_1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_dec_1,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mn_dec_2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.n_dec_2,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mepochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.epochs,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mlr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.learning_rate,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.batch_size,\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mlatent_dim\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.latent_dim,\u001b[37m\u001b[39;49;00m\n",
      "        }\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m tf.device(\u001b[33m\"\u001b[39;49;00m\u001b[33m/device:GPU:0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            ae = AutoEncoderTrainOnly(x, params)\u001b[37m\u001b[39;49;00m\n",
      "            ae.fit()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Save the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# A version number is needed for the serving container\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# to load the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        version = \u001b[33m\"\u001b[39;49;00m\u001b[33m00000000\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        ckpt_dir = os.path.join(args.model_dir, version, \u001b[33m\"\u001b[39;49;00m\u001b[33m.h5\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.exists(ckpt_dir):\u001b[37m\u001b[39;49;00m\n",
      "            os.makedirs(ckpt_dir)\u001b[37m\u001b[39;49;00m\n",
      "        ae.model.save(ckpt_dir)\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    tj = TrainingJob()\u001b[37m\u001b[39;49;00m\n",
      "    tj.run()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize '../trainer/autoencoder.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1e150b-3899-461e-87c1-ab7f5c4d64fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set local_mode to be True if you want to run the training script on the machine that runs this notebook\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.g4dn.8xlarge\"\n",
    "\n",
    "output_path = \"s3://kedrobucket/supply_chain_data_asset_shr/training/jane_st_forecasting\"\n",
    "est = TensorFlow(\n",
    "    entry_point=\"autoencoder.py\",\n",
    "    source_dir=\"../trainer\",  # directory of your training script\n",
    "    role=role,\n",
    "    framework_version=\"2.16\",\n",
    "    model_dir=False,  # don't pass --model_dir to your training script\n",
    "    py_version=\"py310\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    volume_size=80,\n",
    "    output_path=output_path,\n",
    "    hyperparameters={\n",
    "        \"batch_size\": 256,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"s3_filename\": \"df_530_lite.npz\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982e017b-e9c6-4094-997c-5e478099b5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels = {\"training\": output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f77d7-9699-4004-bd37-7f1ea40ca45b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: tensorflow-training-2024-10-25-01-06-43-368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-25 01:06:45 Starting - Starting the training job...\n",
      "2024-10-25 01:07:00 Starting - Preparing the instances for training...\n",
      "2024-10-25 01:07:41 Downloading - Downloading input data....................."
     ]
    }
   ],
   "source": [
    "est.fit(inputs=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69177d03-5b2c-4328-bdd8-a475144b82f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download outputs to local\n",
    "local_path = est.model_data.split(\"jane_st_forecasting/\")[1]\n",
    "s3_path = est.model_data\n",
    "\n",
    "!aws s3 cp {s3_path} {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d5cef-5072-41bf-9976-e00487dfb726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract downloaded outputs\n",
    "\n",
    "import tarfile\n",
    "\n",
    "# Specify the tar file and the directory to extract it to\n",
    "extract_to_dir = 'model'\n",
    "\n",
    "# Open the tar file\n",
    "with tarfile.open(local_path, \"r:gz\") as tar:  # Use \"r\" for uncompressed .tar files\n",
    "    tar.extractall(path=local_path.replace(\".tar.gz\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88109460-d3ef-4488-98af-ba16e3783f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
